{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import walk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(rescale=1/255.)\n",
    "valid_datagen = ImageDataGenerator(rescale=1/255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3068 images belonging to 10 classes.\n",
      "Found 341 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory('train', \n",
    "                        target_size=(250, 250), batch_size=20)\n",
    "valid_generator = valid_datagen.flow_from_directory('validation',\n",
    "                        target_size=(250, 250), batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras.applications.vgg16 import VGG16\n",
    "from keras.applications import VGG19\n",
    "from keras.layers import Flatten, Dense, Input, Dropout\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "vgg = VGG19(weights=\"imagenet\", include_top=False, \n",
    "            input_tensor=Input(shape=(250, 250, 3)))\n",
    "vgg.trainable = False\n",
    "\n",
    "\n",
    "flatten = vgg.output\n",
    "flatten = Flatten()(flatten)\n",
    "bboxHead = Dense(128, activation=\"relu\")(flatten)\n",
    "#bboxHead = Dropout(.3)(bboxHead)\n",
    "bboxHead = Dense(64, activation=\"relu\")(bboxHead)\n",
    "#bboxHead = Dropout(.2)(bboxHead)\n",
    "bboxHead = Dense(32, activation=\"relu\")(bboxHead)\n",
    "#bboxHead = Dropout(.1)(bboxHead)\n",
    "bboxHead = Dense(10, activation=\"softmax\")(bboxHead)\n",
    "# construct the model we will fine-tune for bounding box regression\n",
    "model = Model(inputs=vgg.input, outputs=bboxHead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 250, 250, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 250, 250, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 250, 250, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 125, 125, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 125, 125, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 125, 125, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 62, 62, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 62, 62, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 62, 62, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 62, 62, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 62, 62, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 31, 31, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 31, 31, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 31, 31, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 31, 31, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 31, 31, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 15, 15, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 15, 15, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 15, 15, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 15, 15, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 15, 15, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               3211392   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 23,246,442\n",
      "Trainable params: 3,222,058\n",
      "Non-trainable params: 20,024,384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LR = 1e-4\n",
    "opt = Adam()\n",
    "model.compile(loss=\"categorical_crossentropy\", \n",
    "              optimizer=opt,  \n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "154/154 [==============================] - 25s 126ms/step - loss: 2.3101 - acc: 0.3247 - val_loss: 0.8497 - val_acc: 0.7273\n",
      "Epoch 2/10\n",
      "154/154 [==============================] - 17s 110ms/step - loss: 0.8220 - acc: 0.7298 - val_loss: 0.6148 - val_acc: 0.7889\n",
      "Epoch 3/10\n",
      "154/154 [==============================] - 17s 110ms/step - loss: 0.5252 - acc: 0.8193 - val_loss: 0.5928 - val_acc: 0.8065\n",
      "Epoch 4/10\n",
      "154/154 [==============================] - 17s 111ms/step - loss: 0.3441 - acc: 0.8748 - val_loss: 0.6896 - val_acc: 0.7889\n",
      "Epoch 5/10\n",
      "154/154 [==============================] - 17s 111ms/step - loss: 0.2524 - acc: 0.9096 - val_loss: 0.7824 - val_acc: 0.7771\n",
      "Epoch 6/10\n",
      "154/154 [==============================] - 17s 111ms/step - loss: 0.1975 - acc: 0.9347 - val_loss: 0.7098 - val_acc: 0.8035\n",
      "Epoch 7/10\n",
      "154/154 [==============================] - 17s 111ms/step - loss: 0.1515 - acc: 0.9539 - val_loss: 0.4563 - val_acc: 0.8622\n",
      "Epoch 8/10\n",
      "154/154 [==============================] - 17s 111ms/step - loss: 0.1049 - acc: 0.9655 - val_loss: 0.6423 - val_acc: 0.8446\n",
      "Epoch 9/10\n",
      "154/154 [==============================] - 17s 112ms/step - loss: 0.0974 - acc: 0.9650 - val_loss: 0.6953 - val_acc: 0.8358\n",
      "Epoch 10/10\n",
      "154/154 [==============================] - 17s 112ms/step - loss: 0.0874 - acc: 0.9691 - val_loss: 1.0317 - val_acc: 0.8094\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13251e4b860>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', metrics=['acc'])\n",
    "model.fit_generator(train_generator, epochs=10, \n",
    "                             validation_data=valid_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: classificator_.hd5\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"classificator_.hd5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = (train_generator.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dress': 0,\n",
       " 'hat': 1,\n",
       " 'longsleeve': 2,\n",
       " 'outwear': 3,\n",
       " 'pants': 4,\n",
       " 'shirt': 5,\n",
       " 'shoes': 6,\n",
       " 'shorts': 7,\n",
       " 'skirt': 8,\n",
       " 't-shirt': 9}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_map"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "08.11: 2часа. Обзор датасета, принято решение обучать на генераторах, кастомная модель дает val_acc=0.65 (baseline)\n",
    "09.11: 2 часа. Импорт VGG19(weghts=imagenet), val_acc=0.87. Были проверены опции: слой Dropout, активация последнего слоя, кол-во эпох, размерность первого слоя\n",
    "10.11: 3 часа. Разметка bounding box датасета\n",
    "11.11: 2 часа. Попытка создать модель регрессии (bounding box) для всех категорий. На вход передаются 3 канала (RGB). Результаты неудовлетворительные, предсказания скатываются к 0 и 1.\n",
    "12:11: 3 часа. Также попытка создать модель регрессии для всех категорий. Добавление дополнительных каналов, (blur+gray), (адаптивный порог, cv2.adaptiveThreshold), (производная Лапласа, cv2.Laplacian). Результаты неудовлетворительные, предсказания скатываются к 0 и 1.\n",
    "13.11: 4 часа. Попытка обучить модель для каждой категории. Использована модель VGG19(weghts=imagenet) с 4 выходами. Результаты хорошие, val_acc=0.85 в среднем.\n",
    "15.11: Попытка связать модель классификации и модель bounding box в один интерфейс. Не представляется возможным, т.к. при сохранении и выгрузке модели bounding box происходит падение качества модели."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
